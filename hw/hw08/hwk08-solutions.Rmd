---
title: "Homework 8"
output: html_document
---

```{css, echo = F}
.soln {
background-color: #E6E6FA;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE, error = TRUE,
                      fig.height = 3)
library(tidyverse)
```

```{r, echo=F}
old <- theme_get()

theme_set(theme(panel.background = element_rect(fill = "#ededfb")))
```

# Preliminaries

- This file should be in `STAT240/homework/hw08` on your local computer.
- Download `superbowl_commercials.csv` to `STAT240/data`.


# Problem 1

We wish to test whether the average person is shorter than the average NBA player. We have data for the whole population of NBA players and know their average height to be 6'6" (78 inches). Let the average height of a non-player be $\mu$.

(a) What are the null and alternative hypotheses for this test?

<span style="color:#5858d0"> $H_0: \mu = 78$, $H_A: \mu < 78$ </span>

(b) The Central Limit Theorem says the sample mean of n individuals is approximated by  $N\Big(\mu, \; \frac{\sigma}{\sqrt{n}}\Big)$, where $\mu$ and $\sigma$ are the expectation and standard deviation of the population. Assume $\sigma$, the standard deviation of all non-player heights, is 4 inches. If the null hypothesis was true, what is the distribution of the sample mean of the heights of 5 non-players? 

<span style="color:#5858d0"> Under the null of $\mu = 78$, the sample mean is given by 
$$N\Big(78, \frac{4}{\sqrt{5}}\Big)$$
</span>


# Problem 2

We wish to test whether the average person is shorter than the average NBA player. We have data for the whole population of NBA players and know their average height to be 6'6" (78 inches). Let the average height of a non-player be $\mu$.

(a) We sample 5 non-players and get the heights (70, 61, 63, 65, 72). What is the sample mean? What is the probability of getting a sample mean smaller than this on the distribution from problem 2?

<span style="color:#5858d0"> The sample mean is $\frac{70+61+63+65+72}{5} = 66.2$. The probability of getting this number or less on the null distribution is extremely close to 0. </span>

```{r, class.source="soln", class.output="soln"}
pnorm(66.2, 78, 4/sqrt(5))
```


(b) What do we conclude about the average height of non-players compared to the average height of an NBA player? Are we completely 100% certain of that conclusion?

<span style="color:#5858d0"> According to the probability in (a), if the average height of non-players was 78, the sample of 5 height we got is incredibly unlikely.  So, it does not seem plausible that the true average height of non-players is 78.  We cannot be 100% sure of this conclusion, since it was made based on a random sample. </span>


# Problem 3

We wish to test whether over 75% of UW-Madison students drink caffeine by taking a random sample of 45 students.

$$H_0: p = 0.75 \quad \text{versus} \quad H_A: p > 0.75$$

We'll use significance level $\alpha = 0.05$.

(a) After completing our survey, we will get $x$, our test statistic, the number of students out of 45 that drink caffeine.  Find the *rejection threshold* for our test. In other words, what values of $x$ on the $Binom(45, 0.75)$ null distribution lead us to reject the null hypothesis?

<span style="color:#5858d0"> The p-value for this binomial test is $P(X \ge x)$, where $X \sim Binom(45, 0.75)$ and $x$ is the number of successes.  If the p-value ends up being less than 0.05, we end up rejecting the null.  So, I'll calculate what the p-value would be for different values of $x$. </span>

```{r, class.source="soln", class.output="soln"}
pvals <- tibble(x = 35:45,
                pval = 1-pbinom(x-1, 45, 0.75))

pvals
```

<span style="color:#5858d0"> An $x$ value of 39 results in a p-value of 0.038, and larger values of $x$ result in even smaller p-values.  So we reject the null if we observe $x$ to be 39, 40, 41, 42, 43, 44, or 45.  </span>

(b) Suppose the true $p = 0.85$.  Based on what you found in (a), what is the probability that we reject $H_0$ from our sample of 45?

<span style="color:#5858d0"> Under this assumption, the test statistic $x$ is actually being drawn from $Binom(45, 0.85)$.  So we need to find the probability that we get a value from 39 to 45 on this distribution. </span>

```{r, class.source="soln", class.output="soln"}
1-pbinom(38, 45, 0.85)
```

<span style="color:#5858d0"> If the actual true value of $p$ is 0.85, there is a 47.8% chance that we make the correct decision to reject the null value of 0.75. </span>

(c) The probability calculated in (b) is the "true positive rate", called *power*. If we decrease $\alpha$ to 0.01, will the power increase or decrease?  How can you tell without having to re-calculate (a) and (b)?

<span style="color:#5858d0"> The power will decrease.  If our $\alpha$ is smaller, then it will be more difficult to reject the null, and fewer values of $x$ that lead to a sufficiently small enough p-value. </span>


# Problem 4

The file `superbowl_commercials.csv` contains a list of advertisements for 10 brands aired during Super Bowls from 2000 to 2020.  Each advertisement is classified according to several characterisitcs.  More information can be found  [here](https://github.com/fivethirtyeight/superbowl-ads).

Transform the data as follows:

- Group the rows by brand
- Count the number of ads described as "Funny"
- Count the total number of ads
- Find the proportion of "Funny" ads for each brand
- Save the dataset to your environment for the later problems
- Print the dataset

```{r}
commercials <- read_csv("../../data/superbowl_commercials.csv")
```


```{r, class.source="soln", class.output="soln"}
commercials_tidy <- commercials %>%
  group_by(Brand) %>%
  summarize(n_funny = sum(Funny), n_tot = n()) %>%
  mutate(p_funny = n_funny/n_tot)

commercials_tidy
```


# Problem 5

Starting from the dataset created in problem 4, count the total number of ads in the dataset, as well as the total number of "Funny" ads.  Build and interpret a 99% CI for $p_{funny}$, the overall proportion of funny ads across all of the brands.  Use the Agresti-Coull adjustment.

```{r, class.source="soln", class.output="soln"}
# Total number of ads (number of rows of original data)
n <- sum(commercials_tidy$n_tot)

# Number of funny ads
x <- sum(commercials_tidy$n_funny)

phat_ac <- (x + 2) / (n + 4)


# Standard error with AC adjustment
se_ac <- sqrt(phat_ac*(1 - phat_ac)/(n+4))

# Critical value
cv <- qnorm(0.995)
```

<span style="color:#5858d0"> Our point estimate for the proportion of funny ads (after applying the AC adjustment) is 0.688.  This gives a standard error of about 0.029.  Finally, the Z critical value for 99% confidence is $z_{0.005} = 2.576. </span>

```{r, class.source="soln", class.output="soln"}
# Find upper and lower bounds of interval
c(phat_ac - cv*se_ac, phat_ac + cv*se_ac)
```

<span style="color:#5858d0"> We are 99% confident that the true proportion of funny advertisements is within (0.613, 0.763). </span>


# Problem 6

Repeat the analysis in problem 5, but build a 99% CI fo for $p_{funny}$ with the Wald adjustment.  How do the two intervals compare?

<span style="color:#5858d0"> Compared to the interval in 2, we use the same Z critical value, but a different point estimate and standard error.  We are not adding any new observations, just using $\hat{p}$ directly in place of $p$. </span>

```{r, class.source="soln", class.output="soln"}
# Total number of ads (number of rows of original data)
n <- sum(commercials_tidy$n_tot)

# Number of funny ads
x <- sum(commercials_tidy$n_funny)

phat <- x / n


# Standard error with AC adjustment
se <- sqrt(phat*(1 - phat)/(n+4))

# Find upper and lower bounds of interval
c(phat - cv*se, phat + cv*se)
```

The 99% Wald CI is (0.616, 0.766).  The two intervals are very similar, but the AC interval is shifted slightly towards 0.5.


# Problem 7

Perform a hypothesis test to determine whether more than half of superbowl ads are funny.  Use hyoptheses
$$H_0: p_{funny} = 0.5 \quad \text{versus}\quad H_A: p_{funny} > 0.5$$
and $\alpha = 0.01$.  Interpret your result in context.

<span style="color:#5858d0"> Under $H_0$, the number of funny ads out of 249 is Binom(249, 0.5).  The observed number of funny ads is $x_{obs} = 172$.  To calculate a p-value, we need to find the probability of seeing 172 *or more* ads that are funny, under the null assumption. </span>

```{r, class.source="soln", class.output="soln"}
1 - pbinom(171, 249, 0.5)
```

<span style="color:#5858d0"> If one-half of advertisements are funny, the proability of seeing our observed data or something more extreme is very small.  Our p-value is much smaller than $\alpha = 0.01$, so we reject $H_0$.  We have evidence that more than half of ads are funny. </span>


# Problem 8

State the model and assumptions you used to perform inference on $p_{funny}$ in problems 5-7.  State one criticism where reality may differ from the assumptions, potentially leading to misleading conclusions.

<span style="color:#5858d0"> The null distribution in my hypothesis test for $p$ assumes the count of funny ads is binomial with $n = 249$ and some success probability $p$.  We use this result to further assume the proportion of funny ads is approximately normal, which is why we built Z confidence intervals. </span>

<span style="color:#5858d0"> These assumptions rely on the BINS assumptions, but I am skeptical about the "S" or same probability assumption.  The $n = 249$ counts the ads across 10 different companies, and different companies might be more or less likely to advertise their product with humor. </span>


